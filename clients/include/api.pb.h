// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: api.proto

#ifndef PROTOBUF_INCLUDED_api_2eproto
#define PROTOBUF_INCLUDED_api_2eproto

#include <string>

#include <google/protobuf/stubs/common.h>

#if GOOGLE_PROTOBUF_VERSION < 3006001
#error This file was generated by a newer version of protoc which is
#error incompatible with your Protocol Buffer headers.  Please update
#error your headers.
#endif
#if 3006001 < GOOGLE_PROTOBUF_MIN_PROTOC_VERSION
#error This file was generated by an older version of protoc which is
#error incompatible with your Protocol Buffer headers.  Please
#error regenerate this file with a newer version of protoc.
#endif

#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/arena.h>
#include <google/protobuf/arenastring.h>
#include <google/protobuf/generated_message_table_driven.h>
#include <google/protobuf/generated_message_util.h>
#include <google/protobuf/inlined_string_field.h>
#include <google/protobuf/metadata.h>
#include <google/protobuf/message.h>
#include <google/protobuf/repeated_field.h>  // IWYU pragma: export
#include <google/protobuf/extension_set.h>  // IWYU pragma: export
#include <google/protobuf/generated_enum_reflection.h>
#include <google/protobuf/unknown_field_set.h>
#include "model_config.pb.h"
// @@protoc_insertion_point(includes)
#define PROTOBUF_INTERNAL_EXPORT_protobuf_api_2eproto 

namespace protobuf_api_2eproto {
// Internal implementation detail -- do not use these members.
struct TableStruct {
  static const ::google::protobuf::internal::ParseTableField entries[];
  static const ::google::protobuf::internal::AuxillaryParseTableField aux[];
  static const ::google::protobuf::internal::ParseTable schema[10];
  static const ::google::protobuf::internal::FieldMetadata field_metadata[];
  static const ::google::protobuf::internal::SerializationTable serialization_table[];
  static const ::google::protobuf::uint32 offsets[];
};
void AddDescriptors();
}  // namespace protobuf_api_2eproto
namespace nvidia {
namespace inferenceserver {
class InferRequestHeader;
class InferRequestHeaderDefaultTypeInternal;
extern InferRequestHeaderDefaultTypeInternal _InferRequestHeader_default_instance_;
class InferRequestHeader_Input;
class InferRequestHeader_InputDefaultTypeInternal;
extern InferRequestHeader_InputDefaultTypeInternal _InferRequestHeader_Input_default_instance_;
class InferRequestHeader_Output;
class InferRequestHeader_OutputDefaultTypeInternal;
extern InferRequestHeader_OutputDefaultTypeInternal _InferRequestHeader_Output_default_instance_;
class InferRequestHeader_Output_Class;
class InferRequestHeader_Output_ClassDefaultTypeInternal;
extern InferRequestHeader_Output_ClassDefaultTypeInternal _InferRequestHeader_Output_Class_default_instance_;
class InferResponseHeader;
class InferResponseHeaderDefaultTypeInternal;
extern InferResponseHeaderDefaultTypeInternal _InferResponseHeader_default_instance_;
class InferResponseHeader_Output;
class InferResponseHeader_OutputDefaultTypeInternal;
extern InferResponseHeader_OutputDefaultTypeInternal _InferResponseHeader_Output_default_instance_;
class InferResponseHeader_Output_Class;
class InferResponseHeader_Output_ClassDefaultTypeInternal;
extern InferResponseHeader_Output_ClassDefaultTypeInternal _InferResponseHeader_Output_Class_default_instance_;
class InferResponseHeader_Output_Classes;
class InferResponseHeader_Output_ClassesDefaultTypeInternal;
extern InferResponseHeader_Output_ClassesDefaultTypeInternal _InferResponseHeader_Output_Classes_default_instance_;
class InferResponseHeader_Output_Raw;
class InferResponseHeader_Output_RawDefaultTypeInternal;
extern InferResponseHeader_Output_RawDefaultTypeInternal _InferResponseHeader_Output_Raw_default_instance_;
class InferSharedMemory;
class InferSharedMemoryDefaultTypeInternal;
extern InferSharedMemoryDefaultTypeInternal _InferSharedMemory_default_instance_;
}  // namespace inferenceserver
}  // namespace nvidia
namespace google {
namespace protobuf {
template<> ::nvidia::inferenceserver::InferRequestHeader* Arena::CreateMaybeMessage<::nvidia::inferenceserver::InferRequestHeader>(Arena*);
template<> ::nvidia::inferenceserver::InferRequestHeader_Input* Arena::CreateMaybeMessage<::nvidia::inferenceserver::InferRequestHeader_Input>(Arena*);
template<> ::nvidia::inferenceserver::InferRequestHeader_Output* Arena::CreateMaybeMessage<::nvidia::inferenceserver::InferRequestHeader_Output>(Arena*);
template<> ::nvidia::inferenceserver::InferRequestHeader_Output_Class* Arena::CreateMaybeMessage<::nvidia::inferenceserver::InferRequestHeader_Output_Class>(Arena*);
template<> ::nvidia::inferenceserver::InferResponseHeader* Arena::CreateMaybeMessage<::nvidia::inferenceserver::InferResponseHeader>(Arena*);
template<> ::nvidia::inferenceserver::InferResponseHeader_Output* Arena::CreateMaybeMessage<::nvidia::inferenceserver::InferResponseHeader_Output>(Arena*);
template<> ::nvidia::inferenceserver::InferResponseHeader_Output_Class* Arena::CreateMaybeMessage<::nvidia::inferenceserver::InferResponseHeader_Output_Class>(Arena*);
template<> ::nvidia::inferenceserver::InferResponseHeader_Output_Classes* Arena::CreateMaybeMessage<::nvidia::inferenceserver::InferResponseHeader_Output_Classes>(Arena*);
template<> ::nvidia::inferenceserver::InferResponseHeader_Output_Raw* Arena::CreateMaybeMessage<::nvidia::inferenceserver::InferResponseHeader_Output_Raw>(Arena*);
template<> ::nvidia::inferenceserver::InferSharedMemory* Arena::CreateMaybeMessage<::nvidia::inferenceserver::InferSharedMemory>(Arena*);
}  // namespace protobuf
}  // namespace google
namespace nvidia {
namespace inferenceserver {

enum InferRequestHeader_Flag {
  InferRequestHeader_Flag_FLAG_NONE = 0,
  InferRequestHeader_Flag_FLAG_SEQUENCE_START = 1,
  InferRequestHeader_Flag_FLAG_SEQUENCE_END = 2,
  InferRequestHeader_Flag_InferRequestHeader_Flag_INT_MIN_SENTINEL_DO_NOT_USE_ = ::google::protobuf::kint32min,
  InferRequestHeader_Flag_InferRequestHeader_Flag_INT_MAX_SENTINEL_DO_NOT_USE_ = ::google::protobuf::kint32max
};
bool InferRequestHeader_Flag_IsValid(int value);
const InferRequestHeader_Flag InferRequestHeader_Flag_Flag_MIN = InferRequestHeader_Flag_FLAG_NONE;
const InferRequestHeader_Flag InferRequestHeader_Flag_Flag_MAX = InferRequestHeader_Flag_FLAG_SEQUENCE_END;
const int InferRequestHeader_Flag_Flag_ARRAYSIZE = InferRequestHeader_Flag_Flag_MAX + 1;

const ::google::protobuf::EnumDescriptor* InferRequestHeader_Flag_descriptor();
inline const ::std::string& InferRequestHeader_Flag_Name(InferRequestHeader_Flag value) {
  return ::google::protobuf::internal::NameOfEnum(
    InferRequestHeader_Flag_descriptor(), value);
}
inline bool InferRequestHeader_Flag_Parse(
    const ::std::string& name, InferRequestHeader_Flag* value) {
  return ::google::protobuf::internal::ParseNamedEnum<InferRequestHeader_Flag>(
    InferRequestHeader_Flag_descriptor(), name, value);
}
// ===================================================================

class InferSharedMemory : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:nvidia.inferenceserver.InferSharedMemory) */ {
 public:
  InferSharedMemory();
  virtual ~InferSharedMemory();

  InferSharedMemory(const InferSharedMemory& from);

  inline InferSharedMemory& operator=(const InferSharedMemory& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  InferSharedMemory(InferSharedMemory&& from) noexcept
    : InferSharedMemory() {
    *this = ::std::move(from);
  }

  inline InferSharedMemory& operator=(InferSharedMemory&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  static const ::google::protobuf::Descriptor* descriptor();
  static const InferSharedMemory& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const InferSharedMemory* internal_default_instance() {
    return reinterpret_cast<const InferSharedMemory*>(
               &_InferSharedMemory_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    0;

  void Swap(InferSharedMemory* other);
  friend void swap(InferSharedMemory& a, InferSharedMemory& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline InferSharedMemory* New() const final {
    return CreateMaybeMessage<InferSharedMemory>(NULL);
  }

  InferSharedMemory* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<InferSharedMemory>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const InferSharedMemory& from);
  void MergeFrom(const InferSharedMemory& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(InferSharedMemory* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // string name = 1;
  void clear_name();
  static const int kNameFieldNumber = 1;
  const ::std::string& name() const;
  void set_name(const ::std::string& value);
  #if LANG_CXX11
  void set_name(::std::string&& value);
  #endif
  void set_name(const char* value);
  void set_name(const char* value, size_t size);
  ::std::string* mutable_name();
  ::std::string* release_name();
  void set_allocated_name(::std::string* name);

  // uint64 offset = 2;
  void clear_offset();
  static const int kOffsetFieldNumber = 2;
  ::google::protobuf::uint64 offset() const;
  void set_offset(::google::protobuf::uint64 value);

  // uint64 byte_size = 3;
  void clear_byte_size();
  static const int kByteSizeFieldNumber = 3;
  ::google::protobuf::uint64 byte_size() const;
  void set_byte_size(::google::protobuf::uint64 value);

  // @@protoc_insertion_point(class_scope:nvidia.inferenceserver.InferSharedMemory)
 private:

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::ArenaStringPtr name_;
  ::google::protobuf::uint64 offset_;
  ::google::protobuf::uint64 byte_size_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  friend struct ::protobuf_api_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class InferRequestHeader_Input : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:nvidia.inferenceserver.InferRequestHeader.Input) */ {
 public:
  InferRequestHeader_Input();
  virtual ~InferRequestHeader_Input();

  InferRequestHeader_Input(const InferRequestHeader_Input& from);

  inline InferRequestHeader_Input& operator=(const InferRequestHeader_Input& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  InferRequestHeader_Input(InferRequestHeader_Input&& from) noexcept
    : InferRequestHeader_Input() {
    *this = ::std::move(from);
  }

  inline InferRequestHeader_Input& operator=(InferRequestHeader_Input&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  static const ::google::protobuf::Descriptor* descriptor();
  static const InferRequestHeader_Input& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const InferRequestHeader_Input* internal_default_instance() {
    return reinterpret_cast<const InferRequestHeader_Input*>(
               &_InferRequestHeader_Input_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    1;

  void Swap(InferRequestHeader_Input* other);
  friend void swap(InferRequestHeader_Input& a, InferRequestHeader_Input& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline InferRequestHeader_Input* New() const final {
    return CreateMaybeMessage<InferRequestHeader_Input>(NULL);
  }

  InferRequestHeader_Input* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<InferRequestHeader_Input>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const InferRequestHeader_Input& from);
  void MergeFrom(const InferRequestHeader_Input& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(InferRequestHeader_Input* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated int64 dims = 2;
  int dims_size() const;
  void clear_dims();
  static const int kDimsFieldNumber = 2;
  ::google::protobuf::int64 dims(int index) const;
  void set_dims(int index, ::google::protobuf::int64 value);
  void add_dims(::google::protobuf::int64 value);
  const ::google::protobuf::RepeatedField< ::google::protobuf::int64 >&
      dims() const;
  ::google::protobuf::RepeatedField< ::google::protobuf::int64 >*
      mutable_dims();

  // string name = 1;
  void clear_name();
  static const int kNameFieldNumber = 1;
  const ::std::string& name() const;
  void set_name(const ::std::string& value);
  #if LANG_CXX11
  void set_name(::std::string&& value);
  #endif
  void set_name(const char* value);
  void set_name(const char* value, size_t size);
  ::std::string* mutable_name();
  ::std::string* release_name();
  void set_allocated_name(::std::string* name);

  // .nvidia.inferenceserver.InferSharedMemory shared_memory = 4;
  bool has_shared_memory() const;
  void clear_shared_memory();
  static const int kSharedMemoryFieldNumber = 4;
  private:
  const ::nvidia::inferenceserver::InferSharedMemory& _internal_shared_memory() const;
  public:
  const ::nvidia::inferenceserver::InferSharedMemory& shared_memory() const;
  ::nvidia::inferenceserver::InferSharedMemory* release_shared_memory();
  ::nvidia::inferenceserver::InferSharedMemory* mutable_shared_memory();
  void set_allocated_shared_memory(::nvidia::inferenceserver::InferSharedMemory* shared_memory);

  // uint64 batch_byte_size = 3;
  void clear_batch_byte_size();
  static const int kBatchByteSizeFieldNumber = 3;
  ::google::protobuf::uint64 batch_byte_size() const;
  void set_batch_byte_size(::google::protobuf::uint64 value);

  // @@protoc_insertion_point(class_scope:nvidia.inferenceserver.InferRequestHeader.Input)
 private:

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::RepeatedField< ::google::protobuf::int64 > dims_;
  mutable int _dims_cached_byte_size_;
  ::google::protobuf::internal::ArenaStringPtr name_;
  ::nvidia::inferenceserver::InferSharedMemory* shared_memory_;
  ::google::protobuf::uint64 batch_byte_size_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  friend struct ::protobuf_api_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class InferRequestHeader_Output_Class : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:nvidia.inferenceserver.InferRequestHeader.Output.Class) */ {
 public:
  InferRequestHeader_Output_Class();
  virtual ~InferRequestHeader_Output_Class();

  InferRequestHeader_Output_Class(const InferRequestHeader_Output_Class& from);

  inline InferRequestHeader_Output_Class& operator=(const InferRequestHeader_Output_Class& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  InferRequestHeader_Output_Class(InferRequestHeader_Output_Class&& from) noexcept
    : InferRequestHeader_Output_Class() {
    *this = ::std::move(from);
  }

  inline InferRequestHeader_Output_Class& operator=(InferRequestHeader_Output_Class&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  static const ::google::protobuf::Descriptor* descriptor();
  static const InferRequestHeader_Output_Class& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const InferRequestHeader_Output_Class* internal_default_instance() {
    return reinterpret_cast<const InferRequestHeader_Output_Class*>(
               &_InferRequestHeader_Output_Class_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    2;

  void Swap(InferRequestHeader_Output_Class* other);
  friend void swap(InferRequestHeader_Output_Class& a, InferRequestHeader_Output_Class& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline InferRequestHeader_Output_Class* New() const final {
    return CreateMaybeMessage<InferRequestHeader_Output_Class>(NULL);
  }

  InferRequestHeader_Output_Class* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<InferRequestHeader_Output_Class>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const InferRequestHeader_Output_Class& from);
  void MergeFrom(const InferRequestHeader_Output_Class& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(InferRequestHeader_Output_Class* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // uint32 count = 1;
  void clear_count();
  static const int kCountFieldNumber = 1;
  ::google::protobuf::uint32 count() const;
  void set_count(::google::protobuf::uint32 value);

  // @@protoc_insertion_point(class_scope:nvidia.inferenceserver.InferRequestHeader.Output.Class)
 private:

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::uint32 count_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  friend struct ::protobuf_api_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class InferRequestHeader_Output : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:nvidia.inferenceserver.InferRequestHeader.Output) */ {
 public:
  InferRequestHeader_Output();
  virtual ~InferRequestHeader_Output();

  InferRequestHeader_Output(const InferRequestHeader_Output& from);

  inline InferRequestHeader_Output& operator=(const InferRequestHeader_Output& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  InferRequestHeader_Output(InferRequestHeader_Output&& from) noexcept
    : InferRequestHeader_Output() {
    *this = ::std::move(from);
  }

  inline InferRequestHeader_Output& operator=(InferRequestHeader_Output&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  static const ::google::protobuf::Descriptor* descriptor();
  static const InferRequestHeader_Output& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const InferRequestHeader_Output* internal_default_instance() {
    return reinterpret_cast<const InferRequestHeader_Output*>(
               &_InferRequestHeader_Output_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    3;

  void Swap(InferRequestHeader_Output* other);
  friend void swap(InferRequestHeader_Output& a, InferRequestHeader_Output& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline InferRequestHeader_Output* New() const final {
    return CreateMaybeMessage<InferRequestHeader_Output>(NULL);
  }

  InferRequestHeader_Output* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<InferRequestHeader_Output>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const InferRequestHeader_Output& from);
  void MergeFrom(const InferRequestHeader_Output& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(InferRequestHeader_Output* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  typedef InferRequestHeader_Output_Class Class;

  // accessors -------------------------------------------------------

  // string name = 1;
  void clear_name();
  static const int kNameFieldNumber = 1;
  const ::std::string& name() const;
  void set_name(const ::std::string& value);
  #if LANG_CXX11
  void set_name(::std::string&& value);
  #endif
  void set_name(const char* value);
  void set_name(const char* value, size_t size);
  ::std::string* mutable_name();
  ::std::string* release_name();
  void set_allocated_name(::std::string* name);

  // .nvidia.inferenceserver.InferRequestHeader.Output.Class cls = 3;
  bool has_cls() const;
  void clear_cls();
  static const int kClsFieldNumber = 3;
  private:
  const ::nvidia::inferenceserver::InferRequestHeader_Output_Class& _internal_cls() const;
  public:
  const ::nvidia::inferenceserver::InferRequestHeader_Output_Class& cls() const;
  ::nvidia::inferenceserver::InferRequestHeader_Output_Class* release_cls();
  ::nvidia::inferenceserver::InferRequestHeader_Output_Class* mutable_cls();
  void set_allocated_cls(::nvidia::inferenceserver::InferRequestHeader_Output_Class* cls);

  // .nvidia.inferenceserver.InferSharedMemory shared_memory = 4;
  bool has_shared_memory() const;
  void clear_shared_memory();
  static const int kSharedMemoryFieldNumber = 4;
  private:
  const ::nvidia::inferenceserver::InferSharedMemory& _internal_shared_memory() const;
  public:
  const ::nvidia::inferenceserver::InferSharedMemory& shared_memory() const;
  ::nvidia::inferenceserver::InferSharedMemory* release_shared_memory();
  ::nvidia::inferenceserver::InferSharedMemory* mutable_shared_memory();
  void set_allocated_shared_memory(::nvidia::inferenceserver::InferSharedMemory* shared_memory);

  // @@protoc_insertion_point(class_scope:nvidia.inferenceserver.InferRequestHeader.Output)
 private:

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::ArenaStringPtr name_;
  ::nvidia::inferenceserver::InferRequestHeader_Output_Class* cls_;
  ::nvidia::inferenceserver::InferSharedMemory* shared_memory_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  friend struct ::protobuf_api_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class InferRequestHeader : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:nvidia.inferenceserver.InferRequestHeader) */ {
 public:
  InferRequestHeader();
  virtual ~InferRequestHeader();

  InferRequestHeader(const InferRequestHeader& from);

  inline InferRequestHeader& operator=(const InferRequestHeader& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  InferRequestHeader(InferRequestHeader&& from) noexcept
    : InferRequestHeader() {
    *this = ::std::move(from);
  }

  inline InferRequestHeader& operator=(InferRequestHeader&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  static const ::google::protobuf::Descriptor* descriptor();
  static const InferRequestHeader& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const InferRequestHeader* internal_default_instance() {
    return reinterpret_cast<const InferRequestHeader*>(
               &_InferRequestHeader_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    4;

  void Swap(InferRequestHeader* other);
  friend void swap(InferRequestHeader& a, InferRequestHeader& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline InferRequestHeader* New() const final {
    return CreateMaybeMessage<InferRequestHeader>(NULL);
  }

  InferRequestHeader* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<InferRequestHeader>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const InferRequestHeader& from);
  void MergeFrom(const InferRequestHeader& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(InferRequestHeader* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  typedef InferRequestHeader_Input Input;
  typedef InferRequestHeader_Output Output;

  typedef InferRequestHeader_Flag Flag;
  static const Flag FLAG_NONE =
    InferRequestHeader_Flag_FLAG_NONE;
  static const Flag FLAG_SEQUENCE_START =
    InferRequestHeader_Flag_FLAG_SEQUENCE_START;
  static const Flag FLAG_SEQUENCE_END =
    InferRequestHeader_Flag_FLAG_SEQUENCE_END;
  static inline bool Flag_IsValid(int value) {
    return InferRequestHeader_Flag_IsValid(value);
  }
  static const Flag Flag_MIN =
    InferRequestHeader_Flag_Flag_MIN;
  static const Flag Flag_MAX =
    InferRequestHeader_Flag_Flag_MAX;
  static const int Flag_ARRAYSIZE =
    InferRequestHeader_Flag_Flag_ARRAYSIZE;
  static inline const ::google::protobuf::EnumDescriptor*
  Flag_descriptor() {
    return InferRequestHeader_Flag_descriptor();
  }
  static inline const ::std::string& Flag_Name(Flag value) {
    return InferRequestHeader_Flag_Name(value);
  }
  static inline bool Flag_Parse(const ::std::string& name,
      Flag* value) {
    return InferRequestHeader_Flag_Parse(name, value);
  }

  // accessors -------------------------------------------------------

  // repeated .nvidia.inferenceserver.InferRequestHeader.Input input = 2;
  int input_size() const;
  void clear_input();
  static const int kInputFieldNumber = 2;
  ::nvidia::inferenceserver::InferRequestHeader_Input* mutable_input(int index);
  ::google::protobuf::RepeatedPtrField< ::nvidia::inferenceserver::InferRequestHeader_Input >*
      mutable_input();
  const ::nvidia::inferenceserver::InferRequestHeader_Input& input(int index) const;
  ::nvidia::inferenceserver::InferRequestHeader_Input* add_input();
  const ::google::protobuf::RepeatedPtrField< ::nvidia::inferenceserver::InferRequestHeader_Input >&
      input() const;

  // repeated .nvidia.inferenceserver.InferRequestHeader.Output output = 3;
  int output_size() const;
  void clear_output();
  static const int kOutputFieldNumber = 3;
  ::nvidia::inferenceserver::InferRequestHeader_Output* mutable_output(int index);
  ::google::protobuf::RepeatedPtrField< ::nvidia::inferenceserver::InferRequestHeader_Output >*
      mutable_output();
  const ::nvidia::inferenceserver::InferRequestHeader_Output& output(int index) const;
  ::nvidia::inferenceserver::InferRequestHeader_Output* add_output();
  const ::google::protobuf::RepeatedPtrField< ::nvidia::inferenceserver::InferRequestHeader_Output >&
      output() const;

  // uint32 batch_size = 1;
  void clear_batch_size();
  static const int kBatchSizeFieldNumber = 1;
  ::google::protobuf::uint32 batch_size() const;
  void set_batch_size(::google::protobuf::uint32 value);

  // uint32 flags = 6;
  void clear_flags();
  static const int kFlagsFieldNumber = 6;
  ::google::protobuf::uint32 flags() const;
  void set_flags(::google::protobuf::uint32 value);

  // uint64 correlation_id = 4;
  void clear_correlation_id();
  static const int kCorrelationIdFieldNumber = 4;
  ::google::protobuf::uint64 correlation_id() const;
  void set_correlation_id(::google::protobuf::uint64 value);

  // uint64 id = 5;
  void clear_id();
  static const int kIdFieldNumber = 5;
  ::google::protobuf::uint64 id() const;
  void set_id(::google::protobuf::uint64 value);

  // uint64 timeout_microseconds = 8;
  void clear_timeout_microseconds();
  static const int kTimeoutMicrosecondsFieldNumber = 8;
  ::google::protobuf::uint64 timeout_microseconds() const;
  void set_timeout_microseconds(::google::protobuf::uint64 value);

  // uint32 priority = 7;
  void clear_priority();
  static const int kPriorityFieldNumber = 7;
  ::google::protobuf::uint32 priority() const;
  void set_priority(::google::protobuf::uint32 value);

  // @@protoc_insertion_point(class_scope:nvidia.inferenceserver.InferRequestHeader)
 private:

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::RepeatedPtrField< ::nvidia::inferenceserver::InferRequestHeader_Input > input_;
  ::google::protobuf::RepeatedPtrField< ::nvidia::inferenceserver::InferRequestHeader_Output > output_;
  ::google::protobuf::uint32 batch_size_;
  ::google::protobuf::uint32 flags_;
  ::google::protobuf::uint64 correlation_id_;
  ::google::protobuf::uint64 id_;
  ::google::protobuf::uint64 timeout_microseconds_;
  ::google::protobuf::uint32 priority_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  friend struct ::protobuf_api_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class InferResponseHeader_Output_Raw : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:nvidia.inferenceserver.InferResponseHeader.Output.Raw) */ {
 public:
  InferResponseHeader_Output_Raw();
  virtual ~InferResponseHeader_Output_Raw();

  InferResponseHeader_Output_Raw(const InferResponseHeader_Output_Raw& from);

  inline InferResponseHeader_Output_Raw& operator=(const InferResponseHeader_Output_Raw& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  InferResponseHeader_Output_Raw(InferResponseHeader_Output_Raw&& from) noexcept
    : InferResponseHeader_Output_Raw() {
    *this = ::std::move(from);
  }

  inline InferResponseHeader_Output_Raw& operator=(InferResponseHeader_Output_Raw&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  static const ::google::protobuf::Descriptor* descriptor();
  static const InferResponseHeader_Output_Raw& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const InferResponseHeader_Output_Raw* internal_default_instance() {
    return reinterpret_cast<const InferResponseHeader_Output_Raw*>(
               &_InferResponseHeader_Output_Raw_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    5;

  void Swap(InferResponseHeader_Output_Raw* other);
  friend void swap(InferResponseHeader_Output_Raw& a, InferResponseHeader_Output_Raw& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline InferResponseHeader_Output_Raw* New() const final {
    return CreateMaybeMessage<InferResponseHeader_Output_Raw>(NULL);
  }

  InferResponseHeader_Output_Raw* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<InferResponseHeader_Output_Raw>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const InferResponseHeader_Output_Raw& from);
  void MergeFrom(const InferResponseHeader_Output_Raw& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(InferResponseHeader_Output_Raw* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated int64 dims = 1;
  int dims_size() const;
  void clear_dims();
  static const int kDimsFieldNumber = 1;
  ::google::protobuf::int64 dims(int index) const;
  void set_dims(int index, ::google::protobuf::int64 value);
  void add_dims(::google::protobuf::int64 value);
  const ::google::protobuf::RepeatedField< ::google::protobuf::int64 >&
      dims() const;
  ::google::protobuf::RepeatedField< ::google::protobuf::int64 >*
      mutable_dims();

  // uint64 batch_byte_size = 2;
  void clear_batch_byte_size();
  static const int kBatchByteSizeFieldNumber = 2;
  ::google::protobuf::uint64 batch_byte_size() const;
  void set_batch_byte_size(::google::protobuf::uint64 value);

  // @@protoc_insertion_point(class_scope:nvidia.inferenceserver.InferResponseHeader.Output.Raw)
 private:

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::RepeatedField< ::google::protobuf::int64 > dims_;
  mutable int _dims_cached_byte_size_;
  ::google::protobuf::uint64 batch_byte_size_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  friend struct ::protobuf_api_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class InferResponseHeader_Output_Class : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:nvidia.inferenceserver.InferResponseHeader.Output.Class) */ {
 public:
  InferResponseHeader_Output_Class();
  virtual ~InferResponseHeader_Output_Class();

  InferResponseHeader_Output_Class(const InferResponseHeader_Output_Class& from);

  inline InferResponseHeader_Output_Class& operator=(const InferResponseHeader_Output_Class& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  InferResponseHeader_Output_Class(InferResponseHeader_Output_Class&& from) noexcept
    : InferResponseHeader_Output_Class() {
    *this = ::std::move(from);
  }

  inline InferResponseHeader_Output_Class& operator=(InferResponseHeader_Output_Class&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  static const ::google::protobuf::Descriptor* descriptor();
  static const InferResponseHeader_Output_Class& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const InferResponseHeader_Output_Class* internal_default_instance() {
    return reinterpret_cast<const InferResponseHeader_Output_Class*>(
               &_InferResponseHeader_Output_Class_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    6;

  void Swap(InferResponseHeader_Output_Class* other);
  friend void swap(InferResponseHeader_Output_Class& a, InferResponseHeader_Output_Class& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline InferResponseHeader_Output_Class* New() const final {
    return CreateMaybeMessage<InferResponseHeader_Output_Class>(NULL);
  }

  InferResponseHeader_Output_Class* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<InferResponseHeader_Output_Class>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const InferResponseHeader_Output_Class& from);
  void MergeFrom(const InferResponseHeader_Output_Class& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(InferResponseHeader_Output_Class* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // string label = 3;
  void clear_label();
  static const int kLabelFieldNumber = 3;
  const ::std::string& label() const;
  void set_label(const ::std::string& value);
  #if LANG_CXX11
  void set_label(::std::string&& value);
  #endif
  void set_label(const char* value);
  void set_label(const char* value, size_t size);
  ::std::string* mutable_label();
  ::std::string* release_label();
  void set_allocated_label(::std::string* label);

  // int32 idx = 1;
  void clear_idx();
  static const int kIdxFieldNumber = 1;
  ::google::protobuf::int32 idx() const;
  void set_idx(::google::protobuf::int32 value);

  // float value = 2;
  void clear_value();
  static const int kValueFieldNumber = 2;
  float value() const;
  void set_value(float value);

  // @@protoc_insertion_point(class_scope:nvidia.inferenceserver.InferResponseHeader.Output.Class)
 private:

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::ArenaStringPtr label_;
  ::google::protobuf::int32 idx_;
  float value_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  friend struct ::protobuf_api_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class InferResponseHeader_Output_Classes : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:nvidia.inferenceserver.InferResponseHeader.Output.Classes) */ {
 public:
  InferResponseHeader_Output_Classes();
  virtual ~InferResponseHeader_Output_Classes();

  InferResponseHeader_Output_Classes(const InferResponseHeader_Output_Classes& from);

  inline InferResponseHeader_Output_Classes& operator=(const InferResponseHeader_Output_Classes& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  InferResponseHeader_Output_Classes(InferResponseHeader_Output_Classes&& from) noexcept
    : InferResponseHeader_Output_Classes() {
    *this = ::std::move(from);
  }

  inline InferResponseHeader_Output_Classes& operator=(InferResponseHeader_Output_Classes&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  static const ::google::protobuf::Descriptor* descriptor();
  static const InferResponseHeader_Output_Classes& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const InferResponseHeader_Output_Classes* internal_default_instance() {
    return reinterpret_cast<const InferResponseHeader_Output_Classes*>(
               &_InferResponseHeader_Output_Classes_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    7;

  void Swap(InferResponseHeader_Output_Classes* other);
  friend void swap(InferResponseHeader_Output_Classes& a, InferResponseHeader_Output_Classes& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline InferResponseHeader_Output_Classes* New() const final {
    return CreateMaybeMessage<InferResponseHeader_Output_Classes>(NULL);
  }

  InferResponseHeader_Output_Classes* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<InferResponseHeader_Output_Classes>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const InferResponseHeader_Output_Classes& from);
  void MergeFrom(const InferResponseHeader_Output_Classes& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(InferResponseHeader_Output_Classes* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated .nvidia.inferenceserver.InferResponseHeader.Output.Class cls = 1;
  int cls_size() const;
  void clear_cls();
  static const int kClsFieldNumber = 1;
  ::nvidia::inferenceserver::InferResponseHeader_Output_Class* mutable_cls(int index);
  ::google::protobuf::RepeatedPtrField< ::nvidia::inferenceserver::InferResponseHeader_Output_Class >*
      mutable_cls();
  const ::nvidia::inferenceserver::InferResponseHeader_Output_Class& cls(int index) const;
  ::nvidia::inferenceserver::InferResponseHeader_Output_Class* add_cls();
  const ::google::protobuf::RepeatedPtrField< ::nvidia::inferenceserver::InferResponseHeader_Output_Class >&
      cls() const;

  // @@protoc_insertion_point(class_scope:nvidia.inferenceserver.InferResponseHeader.Output.Classes)
 private:

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::RepeatedPtrField< ::nvidia::inferenceserver::InferResponseHeader_Output_Class > cls_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  friend struct ::protobuf_api_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class InferResponseHeader_Output : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:nvidia.inferenceserver.InferResponseHeader.Output) */ {
 public:
  InferResponseHeader_Output();
  virtual ~InferResponseHeader_Output();

  InferResponseHeader_Output(const InferResponseHeader_Output& from);

  inline InferResponseHeader_Output& operator=(const InferResponseHeader_Output& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  InferResponseHeader_Output(InferResponseHeader_Output&& from) noexcept
    : InferResponseHeader_Output() {
    *this = ::std::move(from);
  }

  inline InferResponseHeader_Output& operator=(InferResponseHeader_Output&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  static const ::google::protobuf::Descriptor* descriptor();
  static const InferResponseHeader_Output& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const InferResponseHeader_Output* internal_default_instance() {
    return reinterpret_cast<const InferResponseHeader_Output*>(
               &_InferResponseHeader_Output_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    8;

  void Swap(InferResponseHeader_Output* other);
  friend void swap(InferResponseHeader_Output& a, InferResponseHeader_Output& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline InferResponseHeader_Output* New() const final {
    return CreateMaybeMessage<InferResponseHeader_Output>(NULL);
  }

  InferResponseHeader_Output* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<InferResponseHeader_Output>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const InferResponseHeader_Output& from);
  void MergeFrom(const InferResponseHeader_Output& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(InferResponseHeader_Output* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  typedef InferResponseHeader_Output_Raw Raw;
  typedef InferResponseHeader_Output_Class Class;
  typedef InferResponseHeader_Output_Classes Classes;

  // accessors -------------------------------------------------------

  // repeated .nvidia.inferenceserver.InferResponseHeader.Output.Classes batch_classes = 3;
  int batch_classes_size() const;
  void clear_batch_classes();
  static const int kBatchClassesFieldNumber = 3;
  ::nvidia::inferenceserver::InferResponseHeader_Output_Classes* mutable_batch_classes(int index);
  ::google::protobuf::RepeatedPtrField< ::nvidia::inferenceserver::InferResponseHeader_Output_Classes >*
      mutable_batch_classes();
  const ::nvidia::inferenceserver::InferResponseHeader_Output_Classes& batch_classes(int index) const;
  ::nvidia::inferenceserver::InferResponseHeader_Output_Classes* add_batch_classes();
  const ::google::protobuf::RepeatedPtrField< ::nvidia::inferenceserver::InferResponseHeader_Output_Classes >&
      batch_classes() const;

  // string name = 1;
  void clear_name();
  static const int kNameFieldNumber = 1;
  const ::std::string& name() const;
  void set_name(const ::std::string& value);
  #if LANG_CXX11
  void set_name(::std::string&& value);
  #endif
  void set_name(const char* value);
  void set_name(const char* value, size_t size);
  ::std::string* mutable_name();
  ::std::string* release_name();
  void set_allocated_name(::std::string* name);

  // .nvidia.inferenceserver.InferResponseHeader.Output.Raw raw = 2;
  bool has_raw() const;
  void clear_raw();
  static const int kRawFieldNumber = 2;
  private:
  const ::nvidia::inferenceserver::InferResponseHeader_Output_Raw& _internal_raw() const;
  public:
  const ::nvidia::inferenceserver::InferResponseHeader_Output_Raw& raw() const;
  ::nvidia::inferenceserver::InferResponseHeader_Output_Raw* release_raw();
  ::nvidia::inferenceserver::InferResponseHeader_Output_Raw* mutable_raw();
  void set_allocated_raw(::nvidia::inferenceserver::InferResponseHeader_Output_Raw* raw);

  // .nvidia.inferenceserver.DataType data_type = 4;
  void clear_data_type();
  static const int kDataTypeFieldNumber = 4;
  ::nvidia::inferenceserver::DataType data_type() const;
  void set_data_type(::nvidia::inferenceserver::DataType value);

  // @@protoc_insertion_point(class_scope:nvidia.inferenceserver.InferResponseHeader.Output)
 private:

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::RepeatedPtrField< ::nvidia::inferenceserver::InferResponseHeader_Output_Classes > batch_classes_;
  ::google::protobuf::internal::ArenaStringPtr name_;
  ::nvidia::inferenceserver::InferResponseHeader_Output_Raw* raw_;
  int data_type_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  friend struct ::protobuf_api_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class InferResponseHeader : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:nvidia.inferenceserver.InferResponseHeader) */ {
 public:
  InferResponseHeader();
  virtual ~InferResponseHeader();

  InferResponseHeader(const InferResponseHeader& from);

  inline InferResponseHeader& operator=(const InferResponseHeader& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  InferResponseHeader(InferResponseHeader&& from) noexcept
    : InferResponseHeader() {
    *this = ::std::move(from);
  }

  inline InferResponseHeader& operator=(InferResponseHeader&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  static const ::google::protobuf::Descriptor* descriptor();
  static const InferResponseHeader& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const InferResponseHeader* internal_default_instance() {
    return reinterpret_cast<const InferResponseHeader*>(
               &_InferResponseHeader_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    9;

  void Swap(InferResponseHeader* other);
  friend void swap(InferResponseHeader& a, InferResponseHeader& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline InferResponseHeader* New() const final {
    return CreateMaybeMessage<InferResponseHeader>(NULL);
  }

  InferResponseHeader* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<InferResponseHeader>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const InferResponseHeader& from);
  void MergeFrom(const InferResponseHeader& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(InferResponseHeader* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  typedef InferResponseHeader_Output Output;

  // accessors -------------------------------------------------------

  // repeated .nvidia.inferenceserver.InferResponseHeader.Output output = 4;
  int output_size() const;
  void clear_output();
  static const int kOutputFieldNumber = 4;
  ::nvidia::inferenceserver::InferResponseHeader_Output* mutable_output(int index);
  ::google::protobuf::RepeatedPtrField< ::nvidia::inferenceserver::InferResponseHeader_Output >*
      mutable_output();
  const ::nvidia::inferenceserver::InferResponseHeader_Output& output(int index) const;
  ::nvidia::inferenceserver::InferResponseHeader_Output* add_output();
  const ::google::protobuf::RepeatedPtrField< ::nvidia::inferenceserver::InferResponseHeader_Output >&
      output() const;

  // string model_name = 1;
  void clear_model_name();
  static const int kModelNameFieldNumber = 1;
  const ::std::string& model_name() const;
  void set_model_name(const ::std::string& value);
  #if LANG_CXX11
  void set_model_name(::std::string&& value);
  #endif
  void set_model_name(const char* value);
  void set_model_name(const char* value, size_t size);
  ::std::string* mutable_model_name();
  ::std::string* release_model_name();
  void set_allocated_model_name(::std::string* model_name);

  // int64 model_version = 2;
  void clear_model_version();
  static const int kModelVersionFieldNumber = 2;
  ::google::protobuf::int64 model_version() const;
  void set_model_version(::google::protobuf::int64 value);

  // uint64 id = 5;
  void clear_id();
  static const int kIdFieldNumber = 5;
  ::google::protobuf::uint64 id() const;
  void set_id(::google::protobuf::uint64 value);

  // uint32 batch_size = 3;
  void clear_batch_size();
  static const int kBatchSizeFieldNumber = 3;
  ::google::protobuf::uint32 batch_size() const;
  void set_batch_size(::google::protobuf::uint32 value);

  // @@protoc_insertion_point(class_scope:nvidia.inferenceserver.InferResponseHeader)
 private:

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::RepeatedPtrField< ::nvidia::inferenceserver::InferResponseHeader_Output > output_;
  ::google::protobuf::internal::ArenaStringPtr model_name_;
  ::google::protobuf::int64 model_version_;
  ::google::protobuf::uint64 id_;
  ::google::protobuf::uint32 batch_size_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  friend struct ::protobuf_api_2eproto::TableStruct;
};
// ===================================================================


// ===================================================================

#ifdef __GNUC__
  #pragma GCC diagnostic push
  #pragma GCC diagnostic ignored "-Wstrict-aliasing"
#endif  // __GNUC__
// InferSharedMemory

// string name = 1;
inline void InferSharedMemory::clear_name() {
  name_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline const ::std::string& InferSharedMemory::name() const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferSharedMemory.name)
  return name_.GetNoArena();
}
inline void InferSharedMemory::set_name(const ::std::string& value) {
  
  name_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:nvidia.inferenceserver.InferSharedMemory.name)
}
#if LANG_CXX11
inline void InferSharedMemory::set_name(::std::string&& value) {
  
  name_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:nvidia.inferenceserver.InferSharedMemory.name)
}
#endif
inline void InferSharedMemory::set_name(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  
  name_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:nvidia.inferenceserver.InferSharedMemory.name)
}
inline void InferSharedMemory::set_name(const char* value, size_t size) {
  
  name_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:nvidia.inferenceserver.InferSharedMemory.name)
}
inline ::std::string* InferSharedMemory::mutable_name() {
  
  // @@protoc_insertion_point(field_mutable:nvidia.inferenceserver.InferSharedMemory.name)
  return name_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* InferSharedMemory::release_name() {
  // @@protoc_insertion_point(field_release:nvidia.inferenceserver.InferSharedMemory.name)
  
  return name_.ReleaseNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void InferSharedMemory::set_allocated_name(::std::string* name) {
  if (name != NULL) {
    
  } else {
    
  }
  name_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), name);
  // @@protoc_insertion_point(field_set_allocated:nvidia.inferenceserver.InferSharedMemory.name)
}

// uint64 offset = 2;
inline void InferSharedMemory::clear_offset() {
  offset_ = GOOGLE_ULONGLONG(0);
}
inline ::google::protobuf::uint64 InferSharedMemory::offset() const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferSharedMemory.offset)
  return offset_;
}
inline void InferSharedMemory::set_offset(::google::protobuf::uint64 value) {
  
  offset_ = value;
  // @@protoc_insertion_point(field_set:nvidia.inferenceserver.InferSharedMemory.offset)
}

// uint64 byte_size = 3;
inline void InferSharedMemory::clear_byte_size() {
  byte_size_ = GOOGLE_ULONGLONG(0);
}
inline ::google::protobuf::uint64 InferSharedMemory::byte_size() const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferSharedMemory.byte_size)
  return byte_size_;
}
inline void InferSharedMemory::set_byte_size(::google::protobuf::uint64 value) {
  
  byte_size_ = value;
  // @@protoc_insertion_point(field_set:nvidia.inferenceserver.InferSharedMemory.byte_size)
}

// -------------------------------------------------------------------

// InferRequestHeader_Input

// string name = 1;
inline void InferRequestHeader_Input::clear_name() {
  name_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline const ::std::string& InferRequestHeader_Input::name() const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferRequestHeader.Input.name)
  return name_.GetNoArena();
}
inline void InferRequestHeader_Input::set_name(const ::std::string& value) {
  
  name_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:nvidia.inferenceserver.InferRequestHeader.Input.name)
}
#if LANG_CXX11
inline void InferRequestHeader_Input::set_name(::std::string&& value) {
  
  name_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:nvidia.inferenceserver.InferRequestHeader.Input.name)
}
#endif
inline void InferRequestHeader_Input::set_name(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  
  name_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:nvidia.inferenceserver.InferRequestHeader.Input.name)
}
inline void InferRequestHeader_Input::set_name(const char* value, size_t size) {
  
  name_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:nvidia.inferenceserver.InferRequestHeader.Input.name)
}
inline ::std::string* InferRequestHeader_Input::mutable_name() {
  
  // @@protoc_insertion_point(field_mutable:nvidia.inferenceserver.InferRequestHeader.Input.name)
  return name_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* InferRequestHeader_Input::release_name() {
  // @@protoc_insertion_point(field_release:nvidia.inferenceserver.InferRequestHeader.Input.name)
  
  return name_.ReleaseNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void InferRequestHeader_Input::set_allocated_name(::std::string* name) {
  if (name != NULL) {
    
  } else {
    
  }
  name_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), name);
  // @@protoc_insertion_point(field_set_allocated:nvidia.inferenceserver.InferRequestHeader.Input.name)
}

// repeated int64 dims = 2;
inline int InferRequestHeader_Input::dims_size() const {
  return dims_.size();
}
inline void InferRequestHeader_Input::clear_dims() {
  dims_.Clear();
}
inline ::google::protobuf::int64 InferRequestHeader_Input::dims(int index) const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferRequestHeader.Input.dims)
  return dims_.Get(index);
}
inline void InferRequestHeader_Input::set_dims(int index, ::google::protobuf::int64 value) {
  dims_.Set(index, value);
  // @@protoc_insertion_point(field_set:nvidia.inferenceserver.InferRequestHeader.Input.dims)
}
inline void InferRequestHeader_Input::add_dims(::google::protobuf::int64 value) {
  dims_.Add(value);
  // @@protoc_insertion_point(field_add:nvidia.inferenceserver.InferRequestHeader.Input.dims)
}
inline const ::google::protobuf::RepeatedField< ::google::protobuf::int64 >&
InferRequestHeader_Input::dims() const {
  // @@protoc_insertion_point(field_list:nvidia.inferenceserver.InferRequestHeader.Input.dims)
  return dims_;
}
inline ::google::protobuf::RepeatedField< ::google::protobuf::int64 >*
InferRequestHeader_Input::mutable_dims() {
  // @@protoc_insertion_point(field_mutable_list:nvidia.inferenceserver.InferRequestHeader.Input.dims)
  return &dims_;
}

// uint64 batch_byte_size = 3;
inline void InferRequestHeader_Input::clear_batch_byte_size() {
  batch_byte_size_ = GOOGLE_ULONGLONG(0);
}
inline ::google::protobuf::uint64 InferRequestHeader_Input::batch_byte_size() const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferRequestHeader.Input.batch_byte_size)
  return batch_byte_size_;
}
inline void InferRequestHeader_Input::set_batch_byte_size(::google::protobuf::uint64 value) {
  
  batch_byte_size_ = value;
  // @@protoc_insertion_point(field_set:nvidia.inferenceserver.InferRequestHeader.Input.batch_byte_size)
}

// .nvidia.inferenceserver.InferSharedMemory shared_memory = 4;
inline bool InferRequestHeader_Input::has_shared_memory() const {
  return this != internal_default_instance() && shared_memory_ != NULL;
}
inline void InferRequestHeader_Input::clear_shared_memory() {
  if (GetArenaNoVirtual() == NULL && shared_memory_ != NULL) {
    delete shared_memory_;
  }
  shared_memory_ = NULL;
}
inline const ::nvidia::inferenceserver::InferSharedMemory& InferRequestHeader_Input::_internal_shared_memory() const {
  return *shared_memory_;
}
inline const ::nvidia::inferenceserver::InferSharedMemory& InferRequestHeader_Input::shared_memory() const {
  const ::nvidia::inferenceserver::InferSharedMemory* p = shared_memory_;
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferRequestHeader.Input.shared_memory)
  return p != NULL ? *p : *reinterpret_cast<const ::nvidia::inferenceserver::InferSharedMemory*>(
      &::nvidia::inferenceserver::_InferSharedMemory_default_instance_);
}
inline ::nvidia::inferenceserver::InferSharedMemory* InferRequestHeader_Input::release_shared_memory() {
  // @@protoc_insertion_point(field_release:nvidia.inferenceserver.InferRequestHeader.Input.shared_memory)
  
  ::nvidia::inferenceserver::InferSharedMemory* temp = shared_memory_;
  shared_memory_ = NULL;
  return temp;
}
inline ::nvidia::inferenceserver::InferSharedMemory* InferRequestHeader_Input::mutable_shared_memory() {
  
  if (shared_memory_ == NULL) {
    auto* p = CreateMaybeMessage<::nvidia::inferenceserver::InferSharedMemory>(GetArenaNoVirtual());
    shared_memory_ = p;
  }
  // @@protoc_insertion_point(field_mutable:nvidia.inferenceserver.InferRequestHeader.Input.shared_memory)
  return shared_memory_;
}
inline void InferRequestHeader_Input::set_allocated_shared_memory(::nvidia::inferenceserver::InferSharedMemory* shared_memory) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete shared_memory_;
  }
  if (shared_memory) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      shared_memory = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, shared_memory, submessage_arena);
    }
    
  } else {
    
  }
  shared_memory_ = shared_memory;
  // @@protoc_insertion_point(field_set_allocated:nvidia.inferenceserver.InferRequestHeader.Input.shared_memory)
}

// -------------------------------------------------------------------

// InferRequestHeader_Output_Class

// uint32 count = 1;
inline void InferRequestHeader_Output_Class::clear_count() {
  count_ = 0u;
}
inline ::google::protobuf::uint32 InferRequestHeader_Output_Class::count() const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferRequestHeader.Output.Class.count)
  return count_;
}
inline void InferRequestHeader_Output_Class::set_count(::google::protobuf::uint32 value) {
  
  count_ = value;
  // @@protoc_insertion_point(field_set:nvidia.inferenceserver.InferRequestHeader.Output.Class.count)
}

// -------------------------------------------------------------------

// InferRequestHeader_Output

// string name = 1;
inline void InferRequestHeader_Output::clear_name() {
  name_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline const ::std::string& InferRequestHeader_Output::name() const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferRequestHeader.Output.name)
  return name_.GetNoArena();
}
inline void InferRequestHeader_Output::set_name(const ::std::string& value) {
  
  name_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:nvidia.inferenceserver.InferRequestHeader.Output.name)
}
#if LANG_CXX11
inline void InferRequestHeader_Output::set_name(::std::string&& value) {
  
  name_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:nvidia.inferenceserver.InferRequestHeader.Output.name)
}
#endif
inline void InferRequestHeader_Output::set_name(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  
  name_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:nvidia.inferenceserver.InferRequestHeader.Output.name)
}
inline void InferRequestHeader_Output::set_name(const char* value, size_t size) {
  
  name_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:nvidia.inferenceserver.InferRequestHeader.Output.name)
}
inline ::std::string* InferRequestHeader_Output::mutable_name() {
  
  // @@protoc_insertion_point(field_mutable:nvidia.inferenceserver.InferRequestHeader.Output.name)
  return name_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* InferRequestHeader_Output::release_name() {
  // @@protoc_insertion_point(field_release:nvidia.inferenceserver.InferRequestHeader.Output.name)
  
  return name_.ReleaseNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void InferRequestHeader_Output::set_allocated_name(::std::string* name) {
  if (name != NULL) {
    
  } else {
    
  }
  name_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), name);
  // @@protoc_insertion_point(field_set_allocated:nvidia.inferenceserver.InferRequestHeader.Output.name)
}

// .nvidia.inferenceserver.InferRequestHeader.Output.Class cls = 3;
inline bool InferRequestHeader_Output::has_cls() const {
  return this != internal_default_instance() && cls_ != NULL;
}
inline void InferRequestHeader_Output::clear_cls() {
  if (GetArenaNoVirtual() == NULL && cls_ != NULL) {
    delete cls_;
  }
  cls_ = NULL;
}
inline const ::nvidia::inferenceserver::InferRequestHeader_Output_Class& InferRequestHeader_Output::_internal_cls() const {
  return *cls_;
}
inline const ::nvidia::inferenceserver::InferRequestHeader_Output_Class& InferRequestHeader_Output::cls() const {
  const ::nvidia::inferenceserver::InferRequestHeader_Output_Class* p = cls_;
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferRequestHeader.Output.cls)
  return p != NULL ? *p : *reinterpret_cast<const ::nvidia::inferenceserver::InferRequestHeader_Output_Class*>(
      &::nvidia::inferenceserver::_InferRequestHeader_Output_Class_default_instance_);
}
inline ::nvidia::inferenceserver::InferRequestHeader_Output_Class* InferRequestHeader_Output::release_cls() {
  // @@protoc_insertion_point(field_release:nvidia.inferenceserver.InferRequestHeader.Output.cls)
  
  ::nvidia::inferenceserver::InferRequestHeader_Output_Class* temp = cls_;
  cls_ = NULL;
  return temp;
}
inline ::nvidia::inferenceserver::InferRequestHeader_Output_Class* InferRequestHeader_Output::mutable_cls() {
  
  if (cls_ == NULL) {
    auto* p = CreateMaybeMessage<::nvidia::inferenceserver::InferRequestHeader_Output_Class>(GetArenaNoVirtual());
    cls_ = p;
  }
  // @@protoc_insertion_point(field_mutable:nvidia.inferenceserver.InferRequestHeader.Output.cls)
  return cls_;
}
inline void InferRequestHeader_Output::set_allocated_cls(::nvidia::inferenceserver::InferRequestHeader_Output_Class* cls) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete cls_;
  }
  if (cls) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      cls = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, cls, submessage_arena);
    }
    
  } else {
    
  }
  cls_ = cls;
  // @@protoc_insertion_point(field_set_allocated:nvidia.inferenceserver.InferRequestHeader.Output.cls)
}

// .nvidia.inferenceserver.InferSharedMemory shared_memory = 4;
inline bool InferRequestHeader_Output::has_shared_memory() const {
  return this != internal_default_instance() && shared_memory_ != NULL;
}
inline void InferRequestHeader_Output::clear_shared_memory() {
  if (GetArenaNoVirtual() == NULL && shared_memory_ != NULL) {
    delete shared_memory_;
  }
  shared_memory_ = NULL;
}
inline const ::nvidia::inferenceserver::InferSharedMemory& InferRequestHeader_Output::_internal_shared_memory() const {
  return *shared_memory_;
}
inline const ::nvidia::inferenceserver::InferSharedMemory& InferRequestHeader_Output::shared_memory() const {
  const ::nvidia::inferenceserver::InferSharedMemory* p = shared_memory_;
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferRequestHeader.Output.shared_memory)
  return p != NULL ? *p : *reinterpret_cast<const ::nvidia::inferenceserver::InferSharedMemory*>(
      &::nvidia::inferenceserver::_InferSharedMemory_default_instance_);
}
inline ::nvidia::inferenceserver::InferSharedMemory* InferRequestHeader_Output::release_shared_memory() {
  // @@protoc_insertion_point(field_release:nvidia.inferenceserver.InferRequestHeader.Output.shared_memory)
  
  ::nvidia::inferenceserver::InferSharedMemory* temp = shared_memory_;
  shared_memory_ = NULL;
  return temp;
}
inline ::nvidia::inferenceserver::InferSharedMemory* InferRequestHeader_Output::mutable_shared_memory() {
  
  if (shared_memory_ == NULL) {
    auto* p = CreateMaybeMessage<::nvidia::inferenceserver::InferSharedMemory>(GetArenaNoVirtual());
    shared_memory_ = p;
  }
  // @@protoc_insertion_point(field_mutable:nvidia.inferenceserver.InferRequestHeader.Output.shared_memory)
  return shared_memory_;
}
inline void InferRequestHeader_Output::set_allocated_shared_memory(::nvidia::inferenceserver::InferSharedMemory* shared_memory) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete shared_memory_;
  }
  if (shared_memory) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      shared_memory = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, shared_memory, submessage_arena);
    }
    
  } else {
    
  }
  shared_memory_ = shared_memory;
  // @@protoc_insertion_point(field_set_allocated:nvidia.inferenceserver.InferRequestHeader.Output.shared_memory)
}

// -------------------------------------------------------------------

// InferRequestHeader

// uint64 id = 5;
inline void InferRequestHeader::clear_id() {
  id_ = GOOGLE_ULONGLONG(0);
}
inline ::google::protobuf::uint64 InferRequestHeader::id() const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferRequestHeader.id)
  return id_;
}
inline void InferRequestHeader::set_id(::google::protobuf::uint64 value) {
  
  id_ = value;
  // @@protoc_insertion_point(field_set:nvidia.inferenceserver.InferRequestHeader.id)
}

// uint32 flags = 6;
inline void InferRequestHeader::clear_flags() {
  flags_ = 0u;
}
inline ::google::protobuf::uint32 InferRequestHeader::flags() const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferRequestHeader.flags)
  return flags_;
}
inline void InferRequestHeader::set_flags(::google::protobuf::uint32 value) {
  
  flags_ = value;
  // @@protoc_insertion_point(field_set:nvidia.inferenceserver.InferRequestHeader.flags)
}

// uint64 correlation_id = 4;
inline void InferRequestHeader::clear_correlation_id() {
  correlation_id_ = GOOGLE_ULONGLONG(0);
}
inline ::google::protobuf::uint64 InferRequestHeader::correlation_id() const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferRequestHeader.correlation_id)
  return correlation_id_;
}
inline void InferRequestHeader::set_correlation_id(::google::protobuf::uint64 value) {
  
  correlation_id_ = value;
  // @@protoc_insertion_point(field_set:nvidia.inferenceserver.InferRequestHeader.correlation_id)
}

// uint32 batch_size = 1;
inline void InferRequestHeader::clear_batch_size() {
  batch_size_ = 0u;
}
inline ::google::protobuf::uint32 InferRequestHeader::batch_size() const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferRequestHeader.batch_size)
  return batch_size_;
}
inline void InferRequestHeader::set_batch_size(::google::protobuf::uint32 value) {
  
  batch_size_ = value;
  // @@protoc_insertion_point(field_set:nvidia.inferenceserver.InferRequestHeader.batch_size)
}

// repeated .nvidia.inferenceserver.InferRequestHeader.Input input = 2;
inline int InferRequestHeader::input_size() const {
  return input_.size();
}
inline void InferRequestHeader::clear_input() {
  input_.Clear();
}
inline ::nvidia::inferenceserver::InferRequestHeader_Input* InferRequestHeader::mutable_input(int index) {
  // @@protoc_insertion_point(field_mutable:nvidia.inferenceserver.InferRequestHeader.input)
  return input_.Mutable(index);
}
inline ::google::protobuf::RepeatedPtrField< ::nvidia::inferenceserver::InferRequestHeader_Input >*
InferRequestHeader::mutable_input() {
  // @@protoc_insertion_point(field_mutable_list:nvidia.inferenceserver.InferRequestHeader.input)
  return &input_;
}
inline const ::nvidia::inferenceserver::InferRequestHeader_Input& InferRequestHeader::input(int index) const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferRequestHeader.input)
  return input_.Get(index);
}
inline ::nvidia::inferenceserver::InferRequestHeader_Input* InferRequestHeader::add_input() {
  // @@protoc_insertion_point(field_add:nvidia.inferenceserver.InferRequestHeader.input)
  return input_.Add();
}
inline const ::google::protobuf::RepeatedPtrField< ::nvidia::inferenceserver::InferRequestHeader_Input >&
InferRequestHeader::input() const {
  // @@protoc_insertion_point(field_list:nvidia.inferenceserver.InferRequestHeader.input)
  return input_;
}

// repeated .nvidia.inferenceserver.InferRequestHeader.Output output = 3;
inline int InferRequestHeader::output_size() const {
  return output_.size();
}
inline void InferRequestHeader::clear_output() {
  output_.Clear();
}
inline ::nvidia::inferenceserver::InferRequestHeader_Output* InferRequestHeader::mutable_output(int index) {
  // @@protoc_insertion_point(field_mutable:nvidia.inferenceserver.InferRequestHeader.output)
  return output_.Mutable(index);
}
inline ::google::protobuf::RepeatedPtrField< ::nvidia::inferenceserver::InferRequestHeader_Output >*
InferRequestHeader::mutable_output() {
  // @@protoc_insertion_point(field_mutable_list:nvidia.inferenceserver.InferRequestHeader.output)
  return &output_;
}
inline const ::nvidia::inferenceserver::InferRequestHeader_Output& InferRequestHeader::output(int index) const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferRequestHeader.output)
  return output_.Get(index);
}
inline ::nvidia::inferenceserver::InferRequestHeader_Output* InferRequestHeader::add_output() {
  // @@protoc_insertion_point(field_add:nvidia.inferenceserver.InferRequestHeader.output)
  return output_.Add();
}
inline const ::google::protobuf::RepeatedPtrField< ::nvidia::inferenceserver::InferRequestHeader_Output >&
InferRequestHeader::output() const {
  // @@protoc_insertion_point(field_list:nvidia.inferenceserver.InferRequestHeader.output)
  return output_;
}

// uint32 priority = 7;
inline void InferRequestHeader::clear_priority() {
  priority_ = 0u;
}
inline ::google::protobuf::uint32 InferRequestHeader::priority() const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferRequestHeader.priority)
  return priority_;
}
inline void InferRequestHeader::set_priority(::google::protobuf::uint32 value) {
  
  priority_ = value;
  // @@protoc_insertion_point(field_set:nvidia.inferenceserver.InferRequestHeader.priority)
}

// uint64 timeout_microseconds = 8;
inline void InferRequestHeader::clear_timeout_microseconds() {
  timeout_microseconds_ = GOOGLE_ULONGLONG(0);
}
inline ::google::protobuf::uint64 InferRequestHeader::timeout_microseconds() const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferRequestHeader.timeout_microseconds)
  return timeout_microseconds_;
}
inline void InferRequestHeader::set_timeout_microseconds(::google::protobuf::uint64 value) {
  
  timeout_microseconds_ = value;
  // @@protoc_insertion_point(field_set:nvidia.inferenceserver.InferRequestHeader.timeout_microseconds)
}

// -------------------------------------------------------------------

// InferResponseHeader_Output_Raw

// repeated int64 dims = 1;
inline int InferResponseHeader_Output_Raw::dims_size() const {
  return dims_.size();
}
inline void InferResponseHeader_Output_Raw::clear_dims() {
  dims_.Clear();
}
inline ::google::protobuf::int64 InferResponseHeader_Output_Raw::dims(int index) const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferResponseHeader.Output.Raw.dims)
  return dims_.Get(index);
}
inline void InferResponseHeader_Output_Raw::set_dims(int index, ::google::protobuf::int64 value) {
  dims_.Set(index, value);
  // @@protoc_insertion_point(field_set:nvidia.inferenceserver.InferResponseHeader.Output.Raw.dims)
}
inline void InferResponseHeader_Output_Raw::add_dims(::google::protobuf::int64 value) {
  dims_.Add(value);
  // @@protoc_insertion_point(field_add:nvidia.inferenceserver.InferResponseHeader.Output.Raw.dims)
}
inline const ::google::protobuf::RepeatedField< ::google::protobuf::int64 >&
InferResponseHeader_Output_Raw::dims() const {
  // @@protoc_insertion_point(field_list:nvidia.inferenceserver.InferResponseHeader.Output.Raw.dims)
  return dims_;
}
inline ::google::protobuf::RepeatedField< ::google::protobuf::int64 >*
InferResponseHeader_Output_Raw::mutable_dims() {
  // @@protoc_insertion_point(field_mutable_list:nvidia.inferenceserver.InferResponseHeader.Output.Raw.dims)
  return &dims_;
}

// uint64 batch_byte_size = 2;
inline void InferResponseHeader_Output_Raw::clear_batch_byte_size() {
  batch_byte_size_ = GOOGLE_ULONGLONG(0);
}
inline ::google::protobuf::uint64 InferResponseHeader_Output_Raw::batch_byte_size() const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferResponseHeader.Output.Raw.batch_byte_size)
  return batch_byte_size_;
}
inline void InferResponseHeader_Output_Raw::set_batch_byte_size(::google::protobuf::uint64 value) {
  
  batch_byte_size_ = value;
  // @@protoc_insertion_point(field_set:nvidia.inferenceserver.InferResponseHeader.Output.Raw.batch_byte_size)
}

// -------------------------------------------------------------------

// InferResponseHeader_Output_Class

// int32 idx = 1;
inline void InferResponseHeader_Output_Class::clear_idx() {
  idx_ = 0;
}
inline ::google::protobuf::int32 InferResponseHeader_Output_Class::idx() const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferResponseHeader.Output.Class.idx)
  return idx_;
}
inline void InferResponseHeader_Output_Class::set_idx(::google::protobuf::int32 value) {
  
  idx_ = value;
  // @@protoc_insertion_point(field_set:nvidia.inferenceserver.InferResponseHeader.Output.Class.idx)
}

// float value = 2;
inline void InferResponseHeader_Output_Class::clear_value() {
  value_ = 0;
}
inline float InferResponseHeader_Output_Class::value() const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferResponseHeader.Output.Class.value)
  return value_;
}
inline void InferResponseHeader_Output_Class::set_value(float value) {
  
  value_ = value;
  // @@protoc_insertion_point(field_set:nvidia.inferenceserver.InferResponseHeader.Output.Class.value)
}

// string label = 3;
inline void InferResponseHeader_Output_Class::clear_label() {
  label_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline const ::std::string& InferResponseHeader_Output_Class::label() const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferResponseHeader.Output.Class.label)
  return label_.GetNoArena();
}
inline void InferResponseHeader_Output_Class::set_label(const ::std::string& value) {
  
  label_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:nvidia.inferenceserver.InferResponseHeader.Output.Class.label)
}
#if LANG_CXX11
inline void InferResponseHeader_Output_Class::set_label(::std::string&& value) {
  
  label_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:nvidia.inferenceserver.InferResponseHeader.Output.Class.label)
}
#endif
inline void InferResponseHeader_Output_Class::set_label(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  
  label_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:nvidia.inferenceserver.InferResponseHeader.Output.Class.label)
}
inline void InferResponseHeader_Output_Class::set_label(const char* value, size_t size) {
  
  label_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:nvidia.inferenceserver.InferResponseHeader.Output.Class.label)
}
inline ::std::string* InferResponseHeader_Output_Class::mutable_label() {
  
  // @@protoc_insertion_point(field_mutable:nvidia.inferenceserver.InferResponseHeader.Output.Class.label)
  return label_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* InferResponseHeader_Output_Class::release_label() {
  // @@protoc_insertion_point(field_release:nvidia.inferenceserver.InferResponseHeader.Output.Class.label)
  
  return label_.ReleaseNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void InferResponseHeader_Output_Class::set_allocated_label(::std::string* label) {
  if (label != NULL) {
    
  } else {
    
  }
  label_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), label);
  // @@protoc_insertion_point(field_set_allocated:nvidia.inferenceserver.InferResponseHeader.Output.Class.label)
}

// -------------------------------------------------------------------

// InferResponseHeader_Output_Classes

// repeated .nvidia.inferenceserver.InferResponseHeader.Output.Class cls = 1;
inline int InferResponseHeader_Output_Classes::cls_size() const {
  return cls_.size();
}
inline void InferResponseHeader_Output_Classes::clear_cls() {
  cls_.Clear();
}
inline ::nvidia::inferenceserver::InferResponseHeader_Output_Class* InferResponseHeader_Output_Classes::mutable_cls(int index) {
  // @@protoc_insertion_point(field_mutable:nvidia.inferenceserver.InferResponseHeader.Output.Classes.cls)
  return cls_.Mutable(index);
}
inline ::google::protobuf::RepeatedPtrField< ::nvidia::inferenceserver::InferResponseHeader_Output_Class >*
InferResponseHeader_Output_Classes::mutable_cls() {
  // @@protoc_insertion_point(field_mutable_list:nvidia.inferenceserver.InferResponseHeader.Output.Classes.cls)
  return &cls_;
}
inline const ::nvidia::inferenceserver::InferResponseHeader_Output_Class& InferResponseHeader_Output_Classes::cls(int index) const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferResponseHeader.Output.Classes.cls)
  return cls_.Get(index);
}
inline ::nvidia::inferenceserver::InferResponseHeader_Output_Class* InferResponseHeader_Output_Classes::add_cls() {
  // @@protoc_insertion_point(field_add:nvidia.inferenceserver.InferResponseHeader.Output.Classes.cls)
  return cls_.Add();
}
inline const ::google::protobuf::RepeatedPtrField< ::nvidia::inferenceserver::InferResponseHeader_Output_Class >&
InferResponseHeader_Output_Classes::cls() const {
  // @@protoc_insertion_point(field_list:nvidia.inferenceserver.InferResponseHeader.Output.Classes.cls)
  return cls_;
}

// -------------------------------------------------------------------

// InferResponseHeader_Output

// string name = 1;
inline void InferResponseHeader_Output::clear_name() {
  name_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline const ::std::string& InferResponseHeader_Output::name() const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferResponseHeader.Output.name)
  return name_.GetNoArena();
}
inline void InferResponseHeader_Output::set_name(const ::std::string& value) {
  
  name_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:nvidia.inferenceserver.InferResponseHeader.Output.name)
}
#if LANG_CXX11
inline void InferResponseHeader_Output::set_name(::std::string&& value) {
  
  name_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:nvidia.inferenceserver.InferResponseHeader.Output.name)
}
#endif
inline void InferResponseHeader_Output::set_name(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  
  name_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:nvidia.inferenceserver.InferResponseHeader.Output.name)
}
inline void InferResponseHeader_Output::set_name(const char* value, size_t size) {
  
  name_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:nvidia.inferenceserver.InferResponseHeader.Output.name)
}
inline ::std::string* InferResponseHeader_Output::mutable_name() {
  
  // @@protoc_insertion_point(field_mutable:nvidia.inferenceserver.InferResponseHeader.Output.name)
  return name_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* InferResponseHeader_Output::release_name() {
  // @@protoc_insertion_point(field_release:nvidia.inferenceserver.InferResponseHeader.Output.name)
  
  return name_.ReleaseNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void InferResponseHeader_Output::set_allocated_name(::std::string* name) {
  if (name != NULL) {
    
  } else {
    
  }
  name_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), name);
  // @@protoc_insertion_point(field_set_allocated:nvidia.inferenceserver.InferResponseHeader.Output.name)
}

// .nvidia.inferenceserver.DataType data_type = 4;
inline void InferResponseHeader_Output::clear_data_type() {
  data_type_ = 0;
}
inline ::nvidia::inferenceserver::DataType InferResponseHeader_Output::data_type() const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferResponseHeader.Output.data_type)
  return static_cast< ::nvidia::inferenceserver::DataType >(data_type_);
}
inline void InferResponseHeader_Output::set_data_type(::nvidia::inferenceserver::DataType value) {
  
  data_type_ = value;
  // @@protoc_insertion_point(field_set:nvidia.inferenceserver.InferResponseHeader.Output.data_type)
}

// .nvidia.inferenceserver.InferResponseHeader.Output.Raw raw = 2;
inline bool InferResponseHeader_Output::has_raw() const {
  return this != internal_default_instance() && raw_ != NULL;
}
inline void InferResponseHeader_Output::clear_raw() {
  if (GetArenaNoVirtual() == NULL && raw_ != NULL) {
    delete raw_;
  }
  raw_ = NULL;
}
inline const ::nvidia::inferenceserver::InferResponseHeader_Output_Raw& InferResponseHeader_Output::_internal_raw() const {
  return *raw_;
}
inline const ::nvidia::inferenceserver::InferResponseHeader_Output_Raw& InferResponseHeader_Output::raw() const {
  const ::nvidia::inferenceserver::InferResponseHeader_Output_Raw* p = raw_;
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferResponseHeader.Output.raw)
  return p != NULL ? *p : *reinterpret_cast<const ::nvidia::inferenceserver::InferResponseHeader_Output_Raw*>(
      &::nvidia::inferenceserver::_InferResponseHeader_Output_Raw_default_instance_);
}
inline ::nvidia::inferenceserver::InferResponseHeader_Output_Raw* InferResponseHeader_Output::release_raw() {
  // @@protoc_insertion_point(field_release:nvidia.inferenceserver.InferResponseHeader.Output.raw)
  
  ::nvidia::inferenceserver::InferResponseHeader_Output_Raw* temp = raw_;
  raw_ = NULL;
  return temp;
}
inline ::nvidia::inferenceserver::InferResponseHeader_Output_Raw* InferResponseHeader_Output::mutable_raw() {
  
  if (raw_ == NULL) {
    auto* p = CreateMaybeMessage<::nvidia::inferenceserver::InferResponseHeader_Output_Raw>(GetArenaNoVirtual());
    raw_ = p;
  }
  // @@protoc_insertion_point(field_mutable:nvidia.inferenceserver.InferResponseHeader.Output.raw)
  return raw_;
}
inline void InferResponseHeader_Output::set_allocated_raw(::nvidia::inferenceserver::InferResponseHeader_Output_Raw* raw) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete raw_;
  }
  if (raw) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      raw = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, raw, submessage_arena);
    }
    
  } else {
    
  }
  raw_ = raw;
  // @@protoc_insertion_point(field_set_allocated:nvidia.inferenceserver.InferResponseHeader.Output.raw)
}

// repeated .nvidia.inferenceserver.InferResponseHeader.Output.Classes batch_classes = 3;
inline int InferResponseHeader_Output::batch_classes_size() const {
  return batch_classes_.size();
}
inline void InferResponseHeader_Output::clear_batch_classes() {
  batch_classes_.Clear();
}
inline ::nvidia::inferenceserver::InferResponseHeader_Output_Classes* InferResponseHeader_Output::mutable_batch_classes(int index) {
  // @@protoc_insertion_point(field_mutable:nvidia.inferenceserver.InferResponseHeader.Output.batch_classes)
  return batch_classes_.Mutable(index);
}
inline ::google::protobuf::RepeatedPtrField< ::nvidia::inferenceserver::InferResponseHeader_Output_Classes >*
InferResponseHeader_Output::mutable_batch_classes() {
  // @@protoc_insertion_point(field_mutable_list:nvidia.inferenceserver.InferResponseHeader.Output.batch_classes)
  return &batch_classes_;
}
inline const ::nvidia::inferenceserver::InferResponseHeader_Output_Classes& InferResponseHeader_Output::batch_classes(int index) const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferResponseHeader.Output.batch_classes)
  return batch_classes_.Get(index);
}
inline ::nvidia::inferenceserver::InferResponseHeader_Output_Classes* InferResponseHeader_Output::add_batch_classes() {
  // @@protoc_insertion_point(field_add:nvidia.inferenceserver.InferResponseHeader.Output.batch_classes)
  return batch_classes_.Add();
}
inline const ::google::protobuf::RepeatedPtrField< ::nvidia::inferenceserver::InferResponseHeader_Output_Classes >&
InferResponseHeader_Output::batch_classes() const {
  // @@protoc_insertion_point(field_list:nvidia.inferenceserver.InferResponseHeader.Output.batch_classes)
  return batch_classes_;
}

// -------------------------------------------------------------------

// InferResponseHeader

// uint64 id = 5;
inline void InferResponseHeader::clear_id() {
  id_ = GOOGLE_ULONGLONG(0);
}
inline ::google::protobuf::uint64 InferResponseHeader::id() const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferResponseHeader.id)
  return id_;
}
inline void InferResponseHeader::set_id(::google::protobuf::uint64 value) {
  
  id_ = value;
  // @@protoc_insertion_point(field_set:nvidia.inferenceserver.InferResponseHeader.id)
}

// string model_name = 1;
inline void InferResponseHeader::clear_model_name() {
  model_name_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline const ::std::string& InferResponseHeader::model_name() const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferResponseHeader.model_name)
  return model_name_.GetNoArena();
}
inline void InferResponseHeader::set_model_name(const ::std::string& value) {
  
  model_name_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:nvidia.inferenceserver.InferResponseHeader.model_name)
}
#if LANG_CXX11
inline void InferResponseHeader::set_model_name(::std::string&& value) {
  
  model_name_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:nvidia.inferenceserver.InferResponseHeader.model_name)
}
#endif
inline void InferResponseHeader::set_model_name(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  
  model_name_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:nvidia.inferenceserver.InferResponseHeader.model_name)
}
inline void InferResponseHeader::set_model_name(const char* value, size_t size) {
  
  model_name_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:nvidia.inferenceserver.InferResponseHeader.model_name)
}
inline ::std::string* InferResponseHeader::mutable_model_name() {
  
  // @@protoc_insertion_point(field_mutable:nvidia.inferenceserver.InferResponseHeader.model_name)
  return model_name_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* InferResponseHeader::release_model_name() {
  // @@protoc_insertion_point(field_release:nvidia.inferenceserver.InferResponseHeader.model_name)
  
  return model_name_.ReleaseNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void InferResponseHeader::set_allocated_model_name(::std::string* model_name) {
  if (model_name != NULL) {
    
  } else {
    
  }
  model_name_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), model_name);
  // @@protoc_insertion_point(field_set_allocated:nvidia.inferenceserver.InferResponseHeader.model_name)
}

// int64 model_version = 2;
inline void InferResponseHeader::clear_model_version() {
  model_version_ = GOOGLE_LONGLONG(0);
}
inline ::google::protobuf::int64 InferResponseHeader::model_version() const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferResponseHeader.model_version)
  return model_version_;
}
inline void InferResponseHeader::set_model_version(::google::protobuf::int64 value) {
  
  model_version_ = value;
  // @@protoc_insertion_point(field_set:nvidia.inferenceserver.InferResponseHeader.model_version)
}

// uint32 batch_size = 3;
inline void InferResponseHeader::clear_batch_size() {
  batch_size_ = 0u;
}
inline ::google::protobuf::uint32 InferResponseHeader::batch_size() const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferResponseHeader.batch_size)
  return batch_size_;
}
inline void InferResponseHeader::set_batch_size(::google::protobuf::uint32 value) {
  
  batch_size_ = value;
  // @@protoc_insertion_point(field_set:nvidia.inferenceserver.InferResponseHeader.batch_size)
}

// repeated .nvidia.inferenceserver.InferResponseHeader.Output output = 4;
inline int InferResponseHeader::output_size() const {
  return output_.size();
}
inline void InferResponseHeader::clear_output() {
  output_.Clear();
}
inline ::nvidia::inferenceserver::InferResponseHeader_Output* InferResponseHeader::mutable_output(int index) {
  // @@protoc_insertion_point(field_mutable:nvidia.inferenceserver.InferResponseHeader.output)
  return output_.Mutable(index);
}
inline ::google::protobuf::RepeatedPtrField< ::nvidia::inferenceserver::InferResponseHeader_Output >*
InferResponseHeader::mutable_output() {
  // @@protoc_insertion_point(field_mutable_list:nvidia.inferenceserver.InferResponseHeader.output)
  return &output_;
}
inline const ::nvidia::inferenceserver::InferResponseHeader_Output& InferResponseHeader::output(int index) const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferResponseHeader.output)
  return output_.Get(index);
}
inline ::nvidia::inferenceserver::InferResponseHeader_Output* InferResponseHeader::add_output() {
  // @@protoc_insertion_point(field_add:nvidia.inferenceserver.InferResponseHeader.output)
  return output_.Add();
}
inline const ::google::protobuf::RepeatedPtrField< ::nvidia::inferenceserver::InferResponseHeader_Output >&
InferResponseHeader::output() const {
  // @@protoc_insertion_point(field_list:nvidia.inferenceserver.InferResponseHeader.output)
  return output_;
}

#ifdef __GNUC__
  #pragma GCC diagnostic pop
#endif  // __GNUC__
// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

}  // namespace inferenceserver
}  // namespace nvidia

namespace google {
namespace protobuf {

template <> struct is_proto_enum< ::nvidia::inferenceserver::InferRequestHeader_Flag> : ::std::true_type {};
template <>
inline const EnumDescriptor* GetEnumDescriptor< ::nvidia::inferenceserver::InferRequestHeader_Flag>() {
  return ::nvidia::inferenceserver::InferRequestHeader_Flag_descriptor();
}

}  // namespace protobuf
}  // namespace google

// @@protoc_insertion_point(global_scope)

#endif  // PROTOBUF_INCLUDED_api_2eproto
